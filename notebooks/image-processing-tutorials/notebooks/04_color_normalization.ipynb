{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use shared utils for persistent data dir and color normalization samples\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "try:\n",
    "    from shared import utils as u\n",
    "except ImportError:\n",
    "    repo_url = \"https://github.com/anand-indx/dp-t25.git\"; dest = \"/content/dp-t25\"\n",
    "    if 'google.colab' in sys.modules and not os.path.exists(dest):\n",
    "        import subprocess\n",
    "        subprocess.run(['git', 'clone', '--depth', '1', repo_url, dest], check=False)\n",
    "        sys.path.insert(0, dest)\n",
    "    else:\n",
    "        # Ensure repo root is on sys.path when running locally\n",
    "        sys.path.insert(0, str(Path.cwd().parents[2]))\n",
    "    from shared import utils as u\n",
    "\n",
    "DATA_DIR = u.get_data_dir()\n",
    "color_data_dir, norm_params = u.ensure_color_normalization_samples(DATA_DIR)\n",
    "print(f\"üìÅ Color normalization samples located at: {color_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download sample tiles/WSI archives into DATA_DIR (set TILES_ZIP_URL or enable defaults)\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file_with_progress(url: str, dst: Path, description: str = \"Downloading\") -> bool:\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            total = int(r.headers.get('content-length', 0))\n",
    "            with open(dst, 'wb') as f, tqdm(total=total, unit='B', unit_scale=True, desc=description) as pbar:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Download failed: {url} ‚Üí {dst}\\n   {e}\")\n",
    "        return False\n",
    "\n",
    "# Configuration: set a tiles ZIP URL to download (optional). You can also place any .zip file into DATA_DIR manually.\n",
    "TILES_ZIP_URL = os.environ.get('TILES_ZIP_URL', '').strip()  # e.g., https://example.com/tiles.zip\n",
    "\n",
    "# Known demo WSI (small) from OpenSlide (for reference); contains a single SVS, not tiles.\n",
    "DEMO_WSI_URL = 'https://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/CMU-1-Small-Region.svs'\n",
    "\n",
    "if TILES_ZIP_URL:\n",
    "    tiles_zip_path = DATA_DIR / Path(TILES_ZIP_URL).name\n",
    "    if not tiles_zip_path.exists():\n",
    "        ok = download_file_with_progress(TILES_ZIP_URL, tiles_zip_path, description=f\"Downloading {tiles_zip_path.name}\")\n",
    "        if ok:\n",
    "            print(f\"‚úÖ Downloaded tiles archive to {tiles_zip_path}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Tiles archive already exists at {tiles_zip_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No TILES_ZIP_URL provided; skipping tile archive download. Place a .zip in DATA_DIR to use real tiles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a7d2b",
   "metadata": {},
   "source": [
    "## Color Normalization\n",
    "\n",
    "Histopathology images can have significant color variations due to differences in staining and scanning. Color normalization aims to reduce this variation.\n",
    "\n",
    "**Our Goals:**\n",
    "1.  Understand the need for color normalization.\n",
    "2.  Implement a simple stain normalization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Use real tiles if available by unzipping archives in DATA_DIR and sampling images\n",
    "import zipfile, random\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TILES_DIR = DATA_DIR / \"tiles\"\n",
    "TILES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Unzip any .zip archives found in DATA_DIR into TILES_DIR\n",
    "for z in list(DATA_DIR.glob(\"*.zip\")):\n",
    "    try:\n",
    "        with zipfile.ZipFile(z, 'r') as zip_ref:\n",
    "            zip_ref.extractall(TILES_DIR)\n",
    "            print(f\"‚úÖ Extracted {z.name} -> {TILES_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to extract {z.name}: {e}\")\n",
    "\n",
    "# Collect candidate image files\n",
    "image_exts = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "candidates = [p for p in TILES_DIR.rglob(\"*\") if p.suffix.lower() in image_exts]\n",
    "\n",
    "source_image = None\n",
    "target_image = None\n",
    "\n",
    "if len(candidates) >= 2:\n",
    "    chosen = random.sample(candidates, 2)\n",
    "    try:\n",
    "        source_image = Image.open(chosen[0]).convert('RGB')\n",
    "        target_image = Image.open(chosen[1]).convert('RGB')\n",
    "        print(f\"üß™ Using real tiles: {chosen[0].name} (source), {chosen[1].name} (target)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load chosen tiles: {e}\")\n",
    "\n",
    "# If not enough tiles, the next cell will generate synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create synthetic stained images only if real tiles weren't found in the previous step\n",
    "if 'source_image' not in globals() or source_image is None or 'target_image' not in globals() or target_image is None:\n",
    "    # For this example, we'll create two \"stained\" images to simulate variation.\n",
    "    # In a real scenario, you would use real image tiles.\n",
    "    def create_stained_image(r_stain, g_stain, b_stain):\n",
    "        # Create a base image (e.g., representing tissue)\n",
    "        base = np.ones((100, 100, 3), dtype=np.uint8) * 250\n",
    "        base[20:80, 20:80, :] = [200, 150, 200]  # A \"tissue\" area\n",
    "        \n",
    "        # Apply \"stain\"\n",
    "        stained = base.astype(np.float32)\n",
    "        stained[:, :, 0] *= r_stain\n",
    "        stained[:, :, 1] *= g_stain\n",
    "        stained[:, :, 2] *= b_stain\n",
    "        \n",
    "        return Image.fromarray(np.clip(stained, 0, 255).astype(np.uint8))\n",
    "\n",
    "    source_image = create_stained_image(0.9, 0.7, 0.85)\n",
    "    target_image = create_stained_image(1.0, 0.8, 0.7)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(source_image); axes[0].set_title('Source Image'); axes[0].axis('off')\n",
    "axes[1].imshow(target_image); axes[1].set_title('Target Image (Reference)'); axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0953eb",
   "metadata": {},
   "source": [
    "### 1. Simple Normalization using Mean and Standard Deviation\n",
    "\n",
    "A common method is to scale the source image's color channels to match the mean and standard deviation of a target (reference) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_color(source, target):\n",
    "    src_img = source.convert('RGB') if hasattr(source, 'mode') else Image.fromarray(source).convert('RGB')\n",
    "    tgt_img = target.convert('RGB') if hasattr(target, 'mode') else Image.fromarray(target).convert('RGB')\n",
    "\n",
    "    source_arr = np.array(src_img, dtype=np.float32)\n",
    "    target_arr = np.array(tgt_img, dtype=np.float32)\n",
    "    \n",
    "    normalized_arr = np.zeros_like(source_arr)\n",
    "    eps = 1e-6\n",
    "    \n",
    "    for i in range(3):  # For each channel (R, G, B)\n",
    "        source_channel = source_arr[:, :, i]\n",
    "        target_channel = target_arr[:, :, i]\n",
    "        \n",
    "        # Get stats\n",
    "        src_mean, src_std = float(np.mean(source_channel)), float(np.std(source_channel))\n",
    "        tgt_mean, tgt_std = float(np.mean(target_channel)), float(np.std(target_channel))\n",
    "        \n",
    "        # Normalize (guard std dev)\n",
    "        scale = tgt_std / max(src_std, eps)\n",
    "        normalized_channel = (source_channel - src_mean) * scale + tgt_mean\n",
    "        normalized_arr[:, :, i] = normalized_channel\n",
    "        \n",
    "    return Image.fromarray(np.clip(normalized_arr, 0, 255).astype(np.uint8))\n",
    "\n",
    "normalized_image = normalize_color(source_image, target_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(source_image); axes[0].set_title('Source')\n",
    "axes[1].imshow(target_image); axes[1].set_title('Target')\n",
    "axes[2].imshow(normalized_image); axes[2].set_title('Normalized')\n",
    "for ax in axes: ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f366077",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Check\n",
    "\n",
    "Let's check the mean of the normalized image's channels. They should be closer to the target's channel means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_means(img):\n",
    "    arr = np.array(img.convert('RGB'), dtype=np.float32)\n",
    "    return np.mean(arr, axis=(0, 1))\n",
    "\n",
    "source_means = channel_means(source_image)\n",
    "target_means = channel_means(target_image)\n",
    "normalized_means = channel_means(normalized_image)\n",
    "\n",
    "print(f\"Source means: {np.round(source_means, 2)}\")\n",
    "print(f\"Target means: {np.round(target_means, 2)}\")\n",
    "print(f\"Normalized means: {np.round(normalized_means, 2)}\")\n",
    "\n",
    "# Check if normalized means are closer to target means (tolerant for real data)\n",
    "closer = np.linalg.norm(normalized_means - target_means) < np.linalg.norm(source_means - target_means)\n",
    "assert closer, \"Normalized image stats are not closer to target; check inputs or tile selection.\"\n",
    "\n",
    "print(\"\\nSUCCESS: Normalized image stats are closer to the target.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
