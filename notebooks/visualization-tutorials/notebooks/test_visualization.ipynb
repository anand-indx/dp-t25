{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c34ce3",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Visualization Skills Assessment\n",
    "\n",
    "## Assessment Overview\n",
    "This notebook tests your mastery of data visualization and analysis techniques for digital pathology. Complete all exercises to demonstrate your skills in:\n",
    "\n",
    "- Data manipulation with pandas\n",
    "- Statistical visualization with matplotlib/seaborn\n",
    "- Heatmap analysis and correlation studies\n",
    "- Dimensionality reduction with UMAP\n",
    "\n",
    "## Instructions\n",
    "1. Read each exercise carefully\n",
    "2. Implement the required solutions\n",
    "3. Run the validation cells to check your work\n",
    "4. Achieve >80% on all assessment criteria\n",
    "\n",
    "Let's test your visualization expertise!\n",
    "</VSCode Cell>\n",
    "\n",
    "<VSCode.Cell language=\"python\">\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Assessment environment ready!\")\n",
    "print(\"ðŸŽ¯ Complete all exercises to pass the visualization assessment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9affa5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate assessment dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic pathology metadata\n",
    "n_samples = 500\n",
    "patient_data = {\n",
    "    'patient_id': [f'P{i:04d}' for i in range(n_samples)],\n",
    "    'age': np.random.normal(65, 15, n_samples).astype(int),\n",
    "    'gender': np.random.choice(['M', 'F'], n_samples, p=[0.45, 0.55]),\n",
    "    'diagnosis': np.random.choice(['Normal', 'Benign', 'Malignant'], n_samples, p=[0.4, 0.35, 0.25]),\n",
    "    'tumor_size': np.random.exponential(2.5, n_samples),\n",
    "    'grade': np.random.choice([1, 2, 3], n_samples, p=[0.3, 0.5, 0.2]),\n",
    "    'ki67_score': np.random.beta(2, 5, n_samples) * 100,\n",
    "    'her2_status': np.random.choice(['Negative', 'Positive'], n_samples, p=[0.75, 0.25]),\n",
    "    'er_status': np.random.choice(['Negative', 'Positive'], n_samples, p=[0.3, 0.7]),\n",
    "    'pr_status': np.random.choice(['Negative', 'Positive'], n_samples, p=[0.4, 0.6])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_pathology = pd.DataFrame(patient_data)\n",
    "\n",
    "# Add some correlations to make it realistic\n",
    "mask_malignant = df_pathology['diagnosis'] == 'Malignant'\n",
    "df_pathology.loc[mask_malignant, 'tumor_size'] *= 1.5\n",
    "df_pathology.loc[mask_malignant, 'ki67_score'] *= 1.3\n",
    "df_pathology.loc[mask_malignant, 'grade'] = np.random.choice([2, 3], mask_malignant.sum(), p=[0.3, 0.7])\n",
    "\n",
    "print(f\"ðŸ“Š Assessment dataset created: {len(df_pathology)} samples\")\n",
    "print(\"\\nðŸ” Dataset preview:\")\n",
    "print(df_pathology.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66dbb3",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Exercise 1: Data Exploration (20 points)\n",
    "\n",
    "**Task**: Create a comprehensive data exploration analysis that includes:\n",
    "1. Summary statistics for numerical variables\n",
    "2. Value counts for categorical variables  \n",
    "3. Missing data analysis\n",
    "4. Basic data quality checks\n",
    "\n",
    "**Requirements**:\n",
    "- Use pandas methods effectively\n",
    "- Present results clearly\n",
    "- Identify any data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8db7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 1: Implement your data exploration here\n",
    "\n",
    "def explore_pathology_data(df):\n",
    "    \"\"\"\n",
    "    Comprehensive data exploration function\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with pathology data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of exploration findings\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Implement comprehensive data exploration\n",
    "    # Hint: Use df.describe(), df.info(), df.isnull().sum(), etc.\n",
    "    \n",
    "    print(\"ðŸ“Š COMPREHENSIVE DATA EXPLORATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "    \n",
    "    # TODO: Add your exploration code here\n",
    "    # Example structure:\n",
    "    # - Numerical summaries\n",
    "    # - Categorical summaries  \n",
    "    # - Missing data analysis\n",
    "    # - Data quality checks\n",
    "    \n",
    "    exploration_results = {\n",
    "        'total_samples': len(df),\n",
    "        'missing_data': df.isnull().sum().sum(),\n",
    "        'numerical_vars': df.select_dtypes(include=[np.number]).columns.tolist(),\n",
    "        'categorical_vars': df.select_dtypes(include=['object']).columns.tolist()\n",
    "    }\n",
    "    \n",
    "    return exploration_results\n",
    "\n",
    "# Test your implementation\n",
    "results = explore_pathology_data(df_pathology)\n",
    "print(f\"\\nâœ… Exploration completed: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16864722",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Exercise 2: Statistical Visualization (25 points)\n",
    "\n",
    "**Task**: Create a comprehensive statistical visualization dashboard with:\n",
    "1. Distribution plots for key numerical variables\n",
    "2. Box plots comparing groups\n",
    "3. Bar plots for categorical variables\n",
    "4. A subplot layout with at least 2x2 grid\n",
    "\n",
    "**Requirements**:\n",
    "- Use matplotlib and seaborn effectively\n",
    "- Include proper titles, labels, and legends\n",
    "- Choose appropriate plot types for each variable\n",
    "- Create publication-ready figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 2: Implement your statistical visualization here\n",
    "\n",
    "def create_statistical_dashboard(df):\n",
    "    \"\"\"\n",
    "    Create comprehensive statistical visualization dashboard\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with pathology data\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Create a 2x3 subplot dashboard\n",
    "    # Suggested plots:\n",
    "    # 1. Age distribution histogram\n",
    "    # 2. Tumor size by diagnosis (box plot)\n",
    "    # 3. Ki67 score distribution by diagnosis\n",
    "    # 4. Grade distribution (bar plot)\n",
    "    # 5. Gender vs diagnosis (stacked bar)\n",
    "    # 6. Correlation heatmap subset\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Pathology Data Statistical Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Age distribution\n",
    "    axes[0, 0].hist(df['age'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 0].set_title('Age Distribution')\n",
    "    axes[0, 0].set_xlabel('Age (years)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # TODO: Complete the remaining plots\n",
    "    # Plot 2: Tumor size by diagnosis\n",
    "    # Plot 3: Ki67 score distribution  \n",
    "    # Plot 4: Grade distribution\n",
    "    # Plot 5: Gender vs diagnosis\n",
    "    # Plot 6: Correlation analysis\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Test your implementation\n",
    "dashboard = create_statistical_dashboard(df_pathology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd0296",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Exercise 3: Advanced Heatmap Analysis (25 points)\n",
    "\n",
    "**Task**: Create an advanced correlation heatmap analysis including:\n",
    "1. Correlation matrix of numerical variables\n",
    "2. Hierarchical clustering of features\n",
    "3. Annotated correlation values\n",
    "4. Custom color scheme appropriate for medical data\n",
    "\n",
    "**Requirements**:\n",
    "- Use seaborn's clustermap or heatmap\n",
    "- Include statistical significance indicators\n",
    "- Proper color scale and annotations\n",
    "- Interpret key correlations in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2358215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 3: Implement your heatmap analysis here\n",
    "\n",
    "def advanced_correlation_analysis(df):\n",
    "    \"\"\"\n",
    "    Advanced correlation and heatmap analysis\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with pathology data\n",
    "    \n",
    "    Returns:\n",
    "        correlation_matrix: numpy array or pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select numerical variables for correlation analysis\n",
    "    numerical_vars = df.select_dtypes(include=[np.number]).columns\n",
    "    print(f\"ðŸ“Š Analyzing correlations for: {list(numerical_vars)}\")\n",
    "    \n",
    "    # TODO: Calculate correlation matrix\n",
    "    corr_matrix = df[numerical_vars].corr()\n",
    "    \n",
    "    # TODO: Create advanced heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create heatmap with clustering\n",
    "    # Hint: Use seaborn.clustermap or seaborn.heatmap\n",
    "    # Include: annot=True, cmap='RdBu_r', center=0\n",
    "    \n",
    "    sns.heatmap(corr_matrix, \n",
    "                annot=True, \n",
    "                cmap='RdBu_r', \n",
    "                center=0,\n",
    "                square=True,\n",
    "                fmt='.2f',\n",
    "                cbar_kws={\"shrink\": .8})\n",
    "    \n",
    "    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # TODO: Identify and print strongest correlations\n",
    "    # Find pairs with |correlation| > 0.3\n",
    "    \n",
    "    return corr_matrix\n",
    "\n",
    "# Test your implementation  \n",
    "corr_results = advanced_correlation_analysis(df_pathology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78d63b",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Exercise 4: UMAP Dimensionality Reduction (30 points)\n",
    "\n",
    "**Task**: Implement UMAP analysis for pathology data including:\n",
    "1. Data preprocessing and scaling\n",
    "2. UMAP embedding with optimized parameters\n",
    "3. Visualization colored by different variables\n",
    "4. Interpretation of clustering patterns\n",
    "\n",
    "**Requirements**:\n",
    "- Proper data preprocessing\n",
    "- Multiple UMAP visualizations with different colorings\n",
    "- Parameter optimization\n",
    "- Clear interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE 4: Implement your UMAP analysis here\n",
    "\n",
    "def umap_pathology_analysis(df):\n",
    "    \"\"\"\n",
    "    UMAP dimensionality reduction analysis for pathology data\n",
    "    \n",
    "    Args:\n",
    "        df: pandas DataFrame with pathology data\n",
    "    \n",
    "    Returns:\n",
    "        umap_embedding: numpy array with 2D embedding coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Prepare data for UMAP\n",
    "    # Select numerical features\n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "    X = df[numerical_features].copy()\n",
    "    \n",
    "    # TODO: Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # TODO: Apply UMAP\n",
    "    # Use appropriate parameters: n_neighbors, min_dist, n_components=2\n",
    "    umap_model = umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    embedding = umap_model.fit_transform(X_scaled)\n",
    "    \n",
    "    # TODO: Create visualization dashboard\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('UMAP Analysis of Pathology Data', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Color by diagnosis\n",
    "    for i, diagnosis in enumerate(df['diagnosis'].unique()):\n",
    "        mask = df['diagnosis'] == diagnosis\n",
    "        axes[0, 0].scatter(embedding[mask, 0], embedding[mask, 1], \n",
    "                          label=diagnosis, alpha=0.7, s=30)\n",
    "    axes[0, 0].set_title('UMAP colored by Diagnosis')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].set_xlabel('UMAP 1')\n",
    "    axes[0, 0].set_ylabel('UMAP 2')\n",
    "    \n",
    "    # TODO: Complete remaining plots\n",
    "    # Plot 2: Color by grade\n",
    "    # Plot 3: Color by age groups\n",
    "    # Plot 4: Color by tumor size quartiles\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Test your implementation\n",
    "umap_embedding = umap_pathology_analysis(df_pathology)\n",
    "print(f\"âœ… UMAP embedding shape: {umap_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa9a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ FINAL ASSESSMENT: Validation and Scoring\n",
    "\n",
    "def validate_visualization_skills():\n",
    "    \"\"\"Validate all visualization exercises and calculate score\"\"\"\n",
    "    \n",
    "    print(\"ðŸ§ª VISUALIZATION SKILLS ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    total_score = 0\n",
    "    max_score = 100\n",
    "    \n",
    "    # Check 1: Data exploration completeness\n",
    "    try:\n",
    "        results = explore_pathology_data(df_pathology)\n",
    "        if results['total_samples'] == 500 and results['missing_data'] == 0:\n",
    "            exploration_score = 20\n",
    "            print(\"âœ… Exercise 1 (Data Exploration): 20/20 points\")\n",
    "        else:\n",
    "            exploration_score = 10\n",
    "            print(\"âš ï¸ Exercise 1 (Data Exploration): 10/20 points - incomplete\")\n",
    "        total_score += exploration_score\n",
    "    except:\n",
    "        print(\"âŒ Exercise 1 (Data Exploration): 0/20 points - error\")\n",
    "    \n",
    "    # Check 2: Statistical visualization\n",
    "    try:\n",
    "        dashboard = create_statistical_dashboard(df_pathology)\n",
    "        if dashboard is not None:\n",
    "            viz_score = 25\n",
    "            print(\"âœ… Exercise 2 (Statistical Visualization): 25/25 points\")\n",
    "        else:\n",
    "            viz_score = 15\n",
    "            print(\"âš ï¸ Exercise 2 (Statistical Visualization): 15/25 points - incomplete\")\n",
    "        total_score += viz_score\n",
    "    except:\n",
    "        print(\"âŒ Exercise 2 (Statistical Visualization): 0/25 points - error\")\n",
    "    \n",
    "    # Check 3: Heatmap analysis  \n",
    "    try:\n",
    "        corr_matrix = advanced_correlation_analysis(df_pathology)\n",
    "        if corr_matrix is not None and corr_matrix.shape[0] > 0:\n",
    "            heatmap_score = 25\n",
    "            print(\"âœ… Exercise 3 (Heatmap Analysis): 25/25 points\")\n",
    "        else:\n",
    "            heatmap_score = 15\n",
    "            print(\"âš ï¸ Exercise 3 (Heatmap Analysis): 15/25 points - incomplete\")\n",
    "        total_score += heatmap_score\n",
    "    except:\n",
    "        print(\"âŒ Exercise 3 (Heatmap Analysis): 0/25 points - error\")\n",
    "    \n",
    "    # Check 4: UMAP analysis\n",
    "    try:\n",
    "        embedding = umap_pathology_analysis(df_pathology)\n",
    "        if embedding.shape == (500, 2):\n",
    "            umap_score = 30\n",
    "            print(\"âœ… Exercise 4 (UMAP Analysis): 30/30 points\")\n",
    "        else:\n",
    "            umap_score = 20\n",
    "            print(\"âš ï¸ Exercise 4 (UMAP Analysis): 20/30 points - incorrect shape\")\n",
    "        total_score += umap_score\n",
    "    except:\n",
    "        print(\"âŒ Exercise 4 (UMAP Analysis): 0/30 points - error\")\n",
    "    \n",
    "    # Final assessment\n",
    "    percentage = (total_score / max_score) * 100\n",
    "    \n",
    "    print(f\"\\nðŸ† FINAL SCORE: {total_score}/{max_score} ({percentage:.1f}%)\")\n",
    "    \n",
    "    if percentage >= 80:\n",
    "        print(\"ðŸŽ‰ CONGRATULATIONS! You've mastered visualization skills!\")\n",
    "        print(\"ðŸš€ Ready to advance to Machine Learning tutorials!\")\n",
    "        grade = \"PASS\"\n",
    "    elif percentage >= 60:\n",
    "        print(\"ðŸ“š Good progress! Review areas for improvement and retry.\")\n",
    "        grade = \"NEEDS IMPROVEMENT\"\n",
    "    else:\n",
    "        print(\"ðŸ“– Keep practicing! Review the tutorial materials and try again.\")\n",
    "        grade = \"NEEDS WORK\"\n",
    "    \n",
    "    assert percentage >= 60, f\"Assessment score too low: {percentage:.1f}%. Minimum 60% required.\"\n",
    "    \n",
    "    return {\n",
    "        'total_score': total_score,\n",
    "        'percentage': percentage,\n",
    "        'grade': grade\n",
    "    }\n",
    "\n",
    "# Run final assessment\n",
    "assessment_results = validate_visualization_skills()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0329c424",
   "metadata": {},
   "source": [
    "## ðŸ“š Assessment Summary\n",
    "\n",
    "### Skills Evaluated\n",
    "1. **Data Exploration** (20%): Pandas proficiency and data understanding\n",
    "2. **Statistical Visualization** (25%): Matplotlib/seaborn mastery and plot design\n",
    "3. **Heatmap Analysis** (25%): Correlation analysis and advanced heatmaps\n",
    "4. **UMAP Analysis** (30%): Dimensionality reduction and pattern recognition\n",
    "\n",
    "### Scoring Criteria\n",
    "- **90-100%**: Expert level - Ready for advanced machine learning\n",
    "- **80-89%**: Proficient - Strong foundation with minor gaps\n",
    "- **60-79%**: Developing - Good understanding, needs more practice\n",
    "- **<60%**: Needs improvement - Review tutorial materials\n",
    "\n",
    "### Key Learning Outcomes\n",
    "âœ… **Data Manipulation**: Effective use of pandas for medical data analysis  \n",
    "âœ… **Statistical Thinking**: Appropriate plot selection and interpretation  \n",
    "âœ… **Visual Design**: Publication-ready figures with proper formatting  \n",
    "âœ… **Advanced Techniques**: UMAP for high-dimensional pathology data  \n",
    "\n",
    "### Next Steps\n",
    "Upon successful completion, you're ready for:\n",
    "- **Machine Learning Classification** tutorials\n",
    "- **Deep Learning with CNNs** for pathology images\n",
    "- **Advanced spatial analysis** techniques\n",
    "\n",
    "ðŸŽ“ **Well done!** You've demonstrated strong visualization skills for digital pathology!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
