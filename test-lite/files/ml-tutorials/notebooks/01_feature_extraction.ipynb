{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7472833",
   "metadata": {},
   "source": [
    "# Feature Extraction for Digital Pathology\n",
    "\n",
    "## Learning Objectives\n",
    "- Extract color histograms from pathology images\n",
    "- Compute texture features using Local Binary Patterns (LBP)\n",
    "- Calculate morphometric features from tissue regions\n",
    "- Prepare feature vectors for machine learning classification\n",
    "\n",
    "## Prerequisites\n",
    "- Basic knowledge of image processing\n",
    "- Familiarity with NumPy and scikit-image\n",
    "- Understanding of histograms and texture analysis\n",
    "\n",
    "Let's start by setting up our environment and downloading sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e952c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage import feature, measure, filters\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")\n",
    "print(\"📚 This tutorial will teach you feature extraction techniques for pathology images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample pathology images\n",
    "def download_sample_data():\n",
    "    \"\"\"Download sample pathology images for feature extraction\"\"\"\n",
    "    os.makedirs('data/pathology_samples', exist_ok=True)\n",
    "    \n",
    "    # Sample URLs (these would be replaced with actual pathology image URLs)\n",
    "    sample_urls = [\n",
    "        'https://via.placeholder.com/512x512/FF69B4/000000?text=Normal+Tissue',\n",
    "        'https://via.placeholder.com/512x512/DC143C/000000?text=Cancer+Tissue',\n",
    "        'https://via.placeholder.com/512x512/32CD32/000000?text=Benign+Tissue'\n",
    "    ]\n",
    "    \n",
    "    filenames = ['normal_tissue.png', 'cancer_tissue.png', 'benign_tissue.png']\n",
    "    \n",
    "    print(\"📥 Downloading sample pathology images...\")\n",
    "    for url, filename in zip(sample_urls, filenames):\n",
    "        filepath = f'data/pathology_samples/{filename}'\n",
    "        if not os.path.exists(filepath):\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"✅ Downloaded: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Note: Using placeholder for {filename}\")\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "# Download the data\n",
    "sample_files = download_sample_data()\n",
    "print(f\"📊 Ready to extract features from {len(sample_files)} sample images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color histogram feature extraction\n",
    "def extract_color_features(image, bins=64):\n",
    "    \"\"\"Extract color histogram features from RGB image\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Extract histogram for each color channel\n",
    "    for channel in range(3):  # RGB channels\n",
    "        hist, _ = np.histogram(image[:,:,channel], bins=bins, range=(0, 256))\n",
    "        # Normalize histogram\n",
    "        hist = hist.astype(float) / (image.shape[0] * image.shape[1])\n",
    "        features.extend(hist)\n",
    "    \n",
    "    # Add color moments (mean, std, skewness)\n",
    "    for channel in range(3):\n",
    "        channel_data = image[:,:,channel].flatten()\n",
    "        features.extend([\n",
    "            np.mean(channel_data),\n",
    "            np.std(channel_data),\n",
    "            np.mean((channel_data - np.mean(channel_data))**3) / np.std(channel_data)**3  # skewness\n",
    "        ])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Test color feature extraction\n",
    "print(\"🎨 Testing color feature extraction...\")\n",
    "test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "color_features = extract_color_features(test_image)\n",
    "print(f\"✅ Extracted {len(color_features)} color features\")\n",
    "print(f\"📊 Feature vector shape: {color_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture feature extraction using Local Binary Patterns (LBP)\n",
    "def extract_texture_features(image, radius=3, n_points=24):\n",
    "    \"\"\"Extract texture features using Local Binary Patterns\"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = rgb2gray(image)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # Compute LBP\n",
    "    lbp = feature.local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute LBP histogram\n",
    "    n_bins = n_points + 2\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    # Add Haralick texture features\n",
    "    try:\n",
    "        # Convert to uint8 for Haralick features\n",
    "        gray_uint8 = (gray_image * 255).astype(np.uint8)\n",
    "        \n",
    "        # Compute GLCM properties\n",
    "        glcm = feature.graycomatrix(gray_uint8, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                                  levels=256, symmetric=True, normed=True)\n",
    "        \n",
    "        # Extract GLCM properties\n",
    "        contrast = feature.graycoprops(glcm, 'contrast').flatten()\n",
    "        dissimilarity = feature.graycoprops(glcm, 'dissimilarity').flatten()\n",
    "        homogeneity = feature.graycoprops(glcm, 'homogeneity').flatten()\n",
    "        energy = feature.graycoprops(glcm, 'energy').flatten()\n",
    "        \n",
    "        texture_features = np.concatenate([lbp_hist, contrast, dissimilarity, homogeneity, energy])\n",
    "    except:\n",
    "        # Fallback to just LBP if GLCM fails\n",
    "        texture_features = lbp_hist\n",
    "    \n",
    "    return texture_features\n",
    "\n",
    "# Test texture feature extraction\n",
    "print(\"🖼️ Testing texture feature extraction...\")\n",
    "texture_features = extract_texture_features(test_image)\n",
    "print(f\"✅ Extracted {len(texture_features)} texture features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1abb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphometric feature extraction\n",
    "def extract_morphometric_features(image, threshold_method='otsu'):\n",
    "    \"\"\"Extract morphometric features from binary segmented regions\"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = rgb2gray(image)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # Apply thresholding to segment regions\n",
    "    if threshold_method == 'otsu':\n",
    "        threshold = filters.threshold_otsu(gray_image)\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    \n",
    "    binary_image = gray_image > threshold\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled_image = measure.label(binary_image)\n",
    "    \n",
    "    # Extract region properties\n",
    "    regions = measure.regionprops(labeled_image)\n",
    "    \n",
    "    # Initialize feature lists\n",
    "    areas = []\n",
    "    perimeters = []\n",
    "    eccentricities = []\n",
    "    solidities = []\n",
    "    \n",
    "    for region in regions:\n",
    "        if region.area > 50:  # Filter small regions\n",
    "            areas.append(region.area)\n",
    "            perimeters.append(region.perimeter)\n",
    "            eccentricities.append(region.eccentricity)\n",
    "            solidities.append(region.solidity)\n",
    "    \n",
    "    # Compute statistical features\n",
    "    morphometric_features = []\n",
    "    for feature_list in [areas, perimeters, eccentricities, solidities]:\n",
    "        if len(feature_list) > 0:\n",
    "            morphometric_features.extend([\n",
    "                np.mean(feature_list),\n",
    "                np.std(feature_list),\n",
    "                np.min(feature_list),\n",
    "                np.max(feature_list),\n",
    "                len(feature_list)  # count\n",
    "            ])\n",
    "        else:\n",
    "            morphometric_features.extend([0, 0, 0, 0, 0])\n",
    "    \n",
    "    return np.array(morphometric_features)\n",
    "\n",
    "# Test morphometric feature extraction\n",
    "print(\"📏 Testing morphometric feature extraction...\")\n",
    "morphometric_features = extract_morphometric_features(test_image)\n",
    "print(f\"✅ Extracted {len(morphometric_features)} morphometric features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined feature extraction pipeline\n",
    "def extract_all_features(image):\n",
    "    \"\"\"Extract all types of features from an image\"\"\"\n",
    "    color_feat = extract_color_features(image)\n",
    "    texture_feat = extract_texture_features(image)\n",
    "    morphometric_feat = extract_morphometric_features(image)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = np.concatenate([color_feat, texture_feat, morphometric_feat])\n",
    "    \n",
    "    return {\n",
    "        'color_features': color_feat,\n",
    "        'texture_features': texture_feat,\n",
    "        'morphometric_features': morphometric_feat,\n",
    "        'all_features': all_features\n",
    "    }\n",
    "\n",
    "# Test complete pipeline\n",
    "print(\"🔄 Testing complete feature extraction pipeline...\")\n",
    "feature_dict = extract_all_features(test_image)\n",
    "\n",
    "print(f\"📊 Feature Summary:\")\n",
    "print(f\"   Color features: {len(feature_dict['color_features'])}\")\n",
    "print(f\"   Texture features: {len(feature_dict['texture_features'])}\")\n",
    "print(f\"   Morphometric features: {len(feature_dict['morphometric_features'])}\")\n",
    "print(f\"   Total features: {len(feature_dict['all_features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and preprocessing\n",
    "def preprocess_features(feature_matrix, labels=None, k_best=100):\n",
    "    \"\"\"Preprocess features with normalization and selection\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    if labels is not None and len(np.unique(labels)) > 1:\n",
    "        # Feature selection using ANOVA F-test\n",
    "        selector = SelectKBest(score_func=f_classif, k=min(k_best, scaled_features.shape[1]))\n",
    "        selected_features = selector.fit_transform(scaled_features, labels)\n",
    "        \n",
    "        print(f\"📊 Selected {selected_features.shape[1]} best features out of {scaled_features.shape[1]}\")\n",
    "        return selected_features, scaler, selector\n",
    "    else:\n",
    "        print(f\"📊 Normalized {scaled_features.shape[1]} features\")\n",
    "        return scaled_features, scaler, None\n",
    "\n",
    "# Example preprocessing\n",
    "print(\"⚙️ Testing feature preprocessing...\")\n",
    "dummy_features = np.random.random((50, 200))  # 50 samples, 200 features\n",
    "dummy_labels = np.random.randint(0, 3, 50)    # 3 classes\n",
    "\n",
    "processed_features, scaler, selector = preprocess_features(dummy_features, dummy_labels)\n",
    "print(f\"✅ Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726774d",
   "metadata": {},
   "source": [
    "## 🎯 Exercise: Feature Extraction Challenge\n",
    "\n",
    "Now it's your turn! Complete the following tasks:\n",
    "\n",
    "1. **Load a real pathology image** (or use the provided samples)\n",
    "2. **Extract all three types of features** (color, texture, morphometric)\n",
    "3. **Analyze the feature distributions** using histograms\n",
    "4. **Compare features** between different tissue types\n",
    "\n",
    "### Expected Output\n",
    "Your feature extraction should produce:\n",
    "- Color features: ~201 features (64×3 histogram bins + 9 moments)\n",
    "- Texture features: ~26-50 features (LBP + GLCM properties)  \n",
    "- Morphometric features: ~20 features (5 metrics × 4 statistics)\n",
    "- Total: ~247-271 features per image\n",
    "\n",
    "### Validation\n",
    "Run the assertion below to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 EXERCISE VALIDATION\n",
    "def validate_feature_extraction():\n",
    "    \"\"\"Validate that feature extraction works correctly\"\"\"\n",
    "    \n",
    "    # Create test image\n",
    "    test_img = np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_all_features(test_img)\n",
    "    \n",
    "    # Validate feature counts\n",
    "    assert len(features['color_features']) >= 100, f\"Expected ≥100 color features, got {len(features['color_features'])}\"\n",
    "    assert len(features['texture_features']) >= 20, f\"Expected ≥20 texture features, got {len(features['texture_features'])}\"\n",
    "    assert len(features['morphometric_features']) >= 15, f\"Expected ≥15 morphometric features, got {len(features['morphometric_features'])}\"\n",
    "    assert len(features['all_features']) >= 200, f\"Expected ≥200 total features, got {len(features['all_features'])}\"\n",
    "    \n",
    "    print(\"🎉 All feature extraction tests passed!\")\n",
    "    print(\"🚀 Ready to move to the next tutorial: Classical ML Classification\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run validation\n",
    "validate_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af7c2a",
   "metadata": {},
   "source": [
    "## 📚 Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Color Feature Extraction**: RGB histograms and color moments for capturing color distribution\n",
    "2. **Texture Feature Extraction**: Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrix (GLCM) properties\n",
    "3. **Morphometric Feature Extraction**: Shape and size measurements from segmented regions\n",
    "4. **Feature Preprocessing**: Normalization and feature selection techniques\n",
    "\n",
    "### Next Steps\n",
    "- **Tutorial 2**: Train classical ML classifiers (Random Forest, SVM) using these features\n",
    "- **Tutorial 3**: Evaluate model performance and cross-validation\n",
    "- **Tutorial 4**: Advanced feature selection and ensemble methods\n",
    "\n",
    "### Key Takeaways\n",
    "- **Feature diversity** is crucial for robust classification\n",
    "- **Preprocessing** improves model performance significantly  \n",
    "- **Feature selection** reduces dimensionality and overfitting\n",
    "- **Domain knowledge** helps in choosing relevant features\n",
    "\n",
    "🎓 **Congratulations!** You've mastered feature extraction for digital pathology!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
