{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7472833",
   "metadata": {},
   "source": [
    "# Feature Extraction for Digital Pathology\n",
    "\n",
    "## Learning Objectives\n",
    "- Extract color histograms from pathology images\n",
    "- Compute texture features using Local Binary Patterns (LBP)\n",
    "- Calculate morphometric features from tissue regions\n",
    "- Prepare feature vectors for machine learning classification\n",
    "\n",
    "## Prerequisites\n",
    "- Basic knowledge of image processing\n",
    "- Familiarity with NumPy and scikit-image\n",
    "- Understanding of histograms and texture analysis\n",
    "\n",
    "Let's start by setting up our environment and downloading sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e952c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage import feature, measure, filters\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"ðŸ“š This tutorial will teach you feature extraction techniques for pathology images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample pathology images\n",
    "def download_sample_data():\n",
    "    \"\"\"Download sample pathology images for feature extraction\"\"\"\n",
    "    os.makedirs('data/pathology_samples', exist_ok=True)\n",
    "    \n",
    "    # Sample URLs (these would be replaced with actual pathology image URLs)\n",
    "    sample_urls = [\n",
    "        'https://via.placeholder.com/512x512/FF69B4/000000?text=Normal+Tissue',\n",
    "        'https://via.placeholder.com/512x512/DC143C/000000?text=Cancer+Tissue',\n",
    "        'https://via.placeholder.com/512x512/32CD32/000000?text=Benign+Tissue'\n",
    "    ]\n",
    "    \n",
    "    filenames = ['normal_tissue.png', 'cancer_tissue.png', 'benign_tissue.png']\n",
    "    \n",
    "    print(\"ðŸ“¥ Downloading sample pathology images...\")\n",
    "    for url, filename in zip(sample_urls, filenames):\n",
    "        filepath = f'data/pathology_samples/{filename}'\n",
    "        if not os.path.exists(filepath):\n",
    "            try:\n",
    "                response = requests.get(url)\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "                print(f\"âœ… Downloaded: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Note: Using placeholder for {filename}\")\n",
    "    \n",
    "    return filenames\n",
    "\n",
    "# Download the data\n",
    "sample_files = download_sample_data()\n",
    "print(f\"ðŸ“Š Ready to extract features from {len(sample_files)} sample images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color histogram feature extraction\n",
    "def extract_color_features(image, bins=64):\n",
    "    \"\"\"Extract color histogram features from RGB image\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Extract histogram for each color channel\n",
    "    for channel in range(3):  # RGB channels\n",
    "        hist, _ = np.histogram(image[:,:,channel], bins=bins, range=(0, 256))\n",
    "        # Normalize histogram\n",
    "        hist = hist.astype(float) / (image.shape[0] * image.shape[1])\n",
    "        features.extend(hist)\n",
    "    \n",
    "    # Add color moments (mean, std, skewness)\n",
    "    for channel in range(3):\n",
    "        channel_data = image[:,:,channel].flatten()\n",
    "        features.extend([\n",
    "            np.mean(channel_data),\n",
    "            np.std(channel_data),\n",
    "            np.mean((channel_data - np.mean(channel_data))**3) / np.std(channel_data)**3  # skewness\n",
    "        ])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Test color feature extraction\n",
    "print(\"ðŸŽ¨ Testing color feature extraction...\")\n",
    "test_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "color_features = extract_color_features(test_image)\n",
    "print(f\"âœ… Extracted {len(color_features)} color features\")\n",
    "print(f\"ðŸ“Š Feature vector shape: {color_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241ddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture feature extraction using Local Binary Patterns (LBP)\n",
    "def extract_texture_features(image, radius=3, n_points=24):\n",
    "    \"\"\"Extract texture features using Local Binary Patterns\"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = rgb2gray(image)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # Compute LBP\n",
    "    lbp = feature.local_binary_pattern(gray_image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute LBP histogram\n",
    "    n_bins = n_points + 2\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    \n",
    "    # Add Haralick texture features\n",
    "    try:\n",
    "        # Convert to uint8 for Haralick features\n",
    "        gray_uint8 = (gray_image * 255).astype(np.uint8)\n",
    "        \n",
    "        # Compute GLCM properties\n",
    "        glcm = feature.graycomatrix(gray_uint8, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], \n",
    "                                  levels=256, symmetric=True, normed=True)\n",
    "        \n",
    "        # Extract GLCM properties\n",
    "        contrast = feature.graycoprops(glcm, 'contrast').flatten()\n",
    "        dissimilarity = feature.graycoprops(glcm, 'dissimilarity').flatten()\n",
    "        homogeneity = feature.graycoprops(glcm, 'homogeneity').flatten()\n",
    "        energy = feature.graycoprops(glcm, 'energy').flatten()\n",
    "        \n",
    "        texture_features = np.concatenate([lbp_hist, contrast, dissimilarity, homogeneity, energy])\n",
    "    except:\n",
    "        # Fallback to just LBP if GLCM fails\n",
    "        texture_features = lbp_hist\n",
    "    \n",
    "    return texture_features\n",
    "\n",
    "# Test texture feature extraction\n",
    "print(\"ðŸ–¼ï¸ Testing texture feature extraction...\")\n",
    "texture_features = extract_texture_features(test_image)\n",
    "print(f\"âœ… Extracted {len(texture_features)} texture features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1abb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphometric feature extraction\n",
    "def extract_morphometric_features(image, threshold_method='otsu'):\n",
    "    \"\"\"Extract morphometric features from binary segmented regions\"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = rgb2gray(image)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # Apply thresholding to segment regions\n",
    "    if threshold_method == 'otsu':\n",
    "        threshold = filters.threshold_otsu(gray_image)\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "    \n",
    "    binary_image = gray_image > threshold\n",
    "    \n",
    "    # Label connected components\n",
    "    labeled_image = measure.label(binary_image)\n",
    "    \n",
    "    # Extract region properties\n",
    "    regions = measure.regionprops(labeled_image)\n",
    "    \n",
    "    # Initialize feature lists\n",
    "    areas = []\n",
    "    perimeters = []\n",
    "    eccentricities = []\n",
    "    solidities = []\n",
    "    \n",
    "    for region in regions:\n",
    "        if region.area > 50:  # Filter small regions\n",
    "            areas.append(region.area)\n",
    "            perimeters.append(region.perimeter)\n",
    "            eccentricities.append(region.eccentricity)\n",
    "            solidities.append(region.solidity)\n",
    "    \n",
    "    # Compute statistical features\n",
    "    morphometric_features = []\n",
    "    for feature_list in [areas, perimeters, eccentricities, solidities]:\n",
    "        if len(feature_list) > 0:\n",
    "            morphometric_features.extend([\n",
    "                np.mean(feature_list),\n",
    "                np.std(feature_list),\n",
    "                np.min(feature_list),\n",
    "                np.max(feature_list),\n",
    "                len(feature_list)  # count\n",
    "            ])\n",
    "        else:\n",
    "            morphometric_features.extend([0, 0, 0, 0, 0])\n",
    "    \n",
    "    return np.array(morphometric_features)\n",
    "\n",
    "# Test morphometric feature extraction\n",
    "print(\"ðŸ“ Testing morphometric feature extraction...\")\n",
    "morphometric_features = extract_morphometric_features(test_image)\n",
    "print(f\"âœ… Extracted {len(morphometric_features)} morphometric features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined feature extraction pipeline\n",
    "def extract_all_features(image):\n",
    "    \"\"\"Extract all types of features from an image\"\"\"\n",
    "    color_feat = extract_color_features(image)\n",
    "    texture_feat = extract_texture_features(image)\n",
    "    morphometric_feat = extract_morphometric_features(image)\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = np.concatenate([color_feat, texture_feat, morphometric_feat])\n",
    "    \n",
    "    return {\n",
    "        'color_features': color_feat,\n",
    "        'texture_features': texture_feat,\n",
    "        'morphometric_features': morphometric_feat,\n",
    "        'all_features': all_features\n",
    "    }\n",
    "\n",
    "# Test complete pipeline\n",
    "print(\"ðŸ”„ Testing complete feature extraction pipeline...\")\n",
    "feature_dict = extract_all_features(test_image)\n",
    "\n",
    "print(f\"ðŸ“Š Feature Summary:\")\n",
    "print(f\"   Color features: {len(feature_dict['color_features'])}\")\n",
    "print(f\"   Texture features: {len(feature_dict['texture_features'])}\")\n",
    "print(f\"   Morphometric features: {len(feature_dict['morphometric_features'])}\")\n",
    "print(f\"   Total features: {len(feature_dict['all_features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection and preprocessing\n",
    "def preprocess_features(feature_matrix, labels=None, k_best=100):\n",
    "    \"\"\"Preprocess features with normalization and selection\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    if labels is not None and len(np.unique(labels)) > 1:\n",
    "        # Feature selection using ANOVA F-test\n",
    "        selector = SelectKBest(score_func=f_classif, k=min(k_best, scaled_features.shape[1]))\n",
    "        selected_features = selector.fit_transform(scaled_features, labels)\n",
    "        \n",
    "        print(f\"ðŸ“Š Selected {selected_features.shape[1]} best features out of {scaled_features.shape[1]}\")\n",
    "        return selected_features, scaler, selector\n",
    "    else:\n",
    "        print(f\"ðŸ“Š Normalized {scaled_features.shape[1]} features\")\n",
    "        return scaled_features, scaler, None\n",
    "\n",
    "# Example preprocessing\n",
    "print(\"âš™ï¸ Testing feature preprocessing...\")\n",
    "dummy_features = np.random.random((50, 200))  # 50 samples, 200 features\n",
    "dummy_labels = np.random.randint(0, 3, 50)    # 3 classes\n",
    "\n",
    "processed_features, scaler, selector = preprocess_features(dummy_features, dummy_labels)\n",
    "print(f\"âœ… Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726774d",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Exercise: Feature Extraction Challenge\n",
    "\n",
    "Now it's your turn! Complete the following tasks:\n",
    "\n",
    "1. **Load a real pathology image** (or use the provided samples)\n",
    "2. **Extract all three types of features** (color, texture, morphometric)\n",
    "3. **Analyze the feature distributions** using histograms\n",
    "4. **Compare features** between different tissue types\n",
    "\n",
    "### Expected Output\n",
    "Your feature extraction should produce:\n",
    "- Color features: ~201 features (64Ã—3 histogram bins + 9 moments)\n",
    "- Texture features: ~26-50 features (LBP + GLCM properties)  \n",
    "- Morphometric features: ~20 features (5 metrics Ã— 4 statistics)\n",
    "- Total: ~247-271 features per image\n",
    "\n",
    "### Validation\n",
    "Run the assertion below to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ EXERCISE VALIDATION\n",
    "def validate_feature_extraction():\n",
    "    \"\"\"Validate that feature extraction works correctly\"\"\"\n",
    "    \n",
    "    # Create test image\n",
    "    test_img = np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_all_features(test_img)\n",
    "    \n",
    "    # Validate feature counts\n",
    "    assert len(features['color_features']) >= 100, f\"Expected â‰¥100 color features, got {len(features['color_features'])}\"\n",
    "    assert len(features['texture_features']) >= 20, f\"Expected â‰¥20 texture features, got {len(features['texture_features'])}\"\n",
    "    assert len(features['morphometric_features']) >= 15, f\"Expected â‰¥15 morphometric features, got {len(features['morphometric_features'])}\"\n",
    "    assert len(features['all_features']) >= 200, f\"Expected â‰¥200 total features, got {len(features['all_features'])}\"\n",
    "    \n",
    "    print(\"ðŸŽ‰ All feature extraction tests passed!\")\n",
    "    print(\"ðŸš€ Ready to move to the next tutorial: Classical ML Classification\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run validation\n",
    "validate_feature_extraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af7c2a",
   "metadata": {},
   "source": [
    "## ðŸ“š Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Color Feature Extraction**: RGB histograms and color moments for capturing color distribution\n",
    "2. **Texture Feature Extraction**: Local Binary Patterns (LBP) and Gray-Level Co-occurrence Matrix (GLCM) properties\n",
    "3. **Morphometric Feature Extraction**: Shape and size measurements from segmented regions\n",
    "4. **Feature Preprocessing**: Normalization and feature selection techniques\n",
    "\n",
    "### Next Steps\n",
    "- **Tutorial 2**: Train classical ML classifiers (Random Forest, SVM) using these features\n",
    "- **Tutorial 3**: Evaluate model performance and cross-validation\n",
    "- **Tutorial 4**: Advanced feature selection and ensemble methods\n",
    "\n",
    "### Key Takeaways\n",
    "- **Feature diversity** is crucial for robust classification\n",
    "- **Preprocessing** improves model performance significantly  \n",
    "- **Feature selection** reduces dimensionality and overfitting\n",
    "- **Domain knowledge** helps in choosing relevant features\n",
    "\n",
    "ðŸŽ“ **Congratulations!** You've mastered feature extraction for digital pathology!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
