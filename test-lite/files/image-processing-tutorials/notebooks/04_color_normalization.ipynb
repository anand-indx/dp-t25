{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Dataset Download for Color Normalization Tutorial\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def download_color_normalization_data():\n",
    "    \"\"\"Download diverse histopathology samples with different staining variations\"\"\"\n",
    "    data_dir = Path(\"../data\")\n",
    "    color_samples_dir = data_dir / \"color_samples\"\n",
    "    color_samples_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Diverse staining samples for color normalization\n",
    "    staining_samples = {\n",
    "        'he_stain_1.jpg': 'https://github.com/jamesdolezal/slideflow/raw/master/docs/source/_static/img/tile_5.jpg',\n",
    "        'he_stain_2.jpg': 'https://github.com/jamesdolezal/slideflow/raw/master/docs/source/_static/img/tile_6.jpg',\n",
    "        'reference_normal.png': 'https://raw.githubusercontent.com/PathologyDataScience/TCGA-BRCA-WSI-Tiles/main/sample_tiles/normal_002.png',\n",
    "        'target_tissue.png': 'https://raw.githubusercontent.com/PathologyDataScience/TCGA-BRCA-WSI-Tiles/main/sample_tiles/tumor_001.png'\n",
    "    }\n",
    "    \n",
    "    # Color normalization parameters for different methods\n",
    "    normalization_params = {\n",
    "        'macenko': {\n",
    "            'luminosity_threshold': 0.8,\n",
    "            'alpha': 1.0,\n",
    "            'beta': 0.15\n",
    "        },\n",
    "        'reinhard': {\n",
    "            'target_mu': [8.74108109, -0.12440419,  0.0444982],\n",
    "            'target_sigma': [0.6135447, 0.10989545, 0.0286032]\n",
    "        },\n",
    "        'vahadane': {\n",
    "            'lambda1': 0.01,\n",
    "            'lambda2': 0.01,\n",
    "            'fast_mode': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save normalization parameters\n",
    "    params_file = color_samples_dir / \"normalization_params.json\"\n",
    "    with open(params_file, 'w') as f:\n",
    "        json.dump(normalization_params, f, indent=2)\n",
    "    print(f\"üìä Saved normalization parameters to {params_file}\")\n",
    "    \n",
    "    print(\"üé® Downloading color normalization samples...\")\n",
    "    download_success = []\n",
    "    \n",
    "    for filename, url in staining_samples.items():\n",
    "        filepath = color_samples_dir / filename\n",
    "        if not filepath.exists():\n",
    "            try:\n",
    "                print(f\"üì• Fetching {filename}...\")\n",
    "                response = requests.get(url, stream=True, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                total_size = int(response.headers.get('content-length', 0))\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    if total_size > 0:\n",
    "                        with tqdm(total=total_size, unit='iB', unit_scale=True, desc=filename) as pbar:\n",
    "                            for chunk in response.iter_content(chunk_size=8192):\n",
    "                                if chunk:\n",
    "                                    f.write(chunk)\n",
    "                                    pbar.update(len(chunk))\n",
    "                    else:\n",
    "                        for chunk in response.iter_content(chunk_size=8192):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                \n",
    "                print(f\"‚úÖ Downloaded {filename} successfully\")\n",
    "                download_success.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error downloading {filename}: {e}\")\n",
    "                # Create synthetic sample for demo purposes\n",
    "                try:\n",
    "                    import numpy as np\n",
    "                    from PIL import Image\n",
    "                    synthetic = np.random.randint(100, 200, (512, 512, 3), dtype=np.uint8)\n",
    "                    # Add some structure to make it look more tissue-like\n",
    "                    synthetic[100:150, 100:150] = [180, 120, 160]  # Purple-ish region\n",
    "                    synthetic[300:400, 200:350] = [220, 180, 190]  # Pink-ish region\n",
    "                    Image.fromarray(synthetic).save(filepath)\n",
    "                    print(f\"üé≠ Created synthetic sample for {filename}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "        else:\n",
    "            print(f\"‚úÖ {filename} already exists\")\n",
    "            download_success.append(filename)\n",
    "    \n",
    "    print(f\"üéØ Color normalization data ready! {len(download_success)}/{len(staining_samples)} samples available\")\n",
    "    print(f\"üìÅ Data location: {color_samples_dir.absolute()}\")\n",
    "    return color_samples_dir, normalization_params\n",
    "\n",
    "# Initialize color normalization data\n",
    "color_data_dir, norm_params = download_color_normalization_data()\n",
    "print(\"üî¨ Ready for color normalization experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a7d2b",
   "metadata": {},
   "source": [
    "## Color Normalization\n",
    "\n",
    "Histopathology images can have significant color variations due to differences in staining and scanning. Color normalization aims to reduce this variation.\n",
    "\n",
    "**Our Goals:**\n",
    "1.  Understand the need for color normalization.\n",
    "2.  Implement a simple stain normalization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff9a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For this example, we'll create two \"stained\" images to simulate variation.\n",
    "# In a real scenario, you would use real image tiles.\n",
    "def create_stained_image(r_stain, g_stain, b_stain):\n",
    "    # Create a base image (e.g., representing tissue)\n",
    "    base = np.ones((100, 100, 3), dtype=np.uint8) * 250\n",
    "    base[20:80, 20:80, :] = [200, 150, 200] # A \"tissue\" area\n",
    "    \n",
    "    # Apply \"stain\"\n",
    "    stained = base.astype(np.float32)\n",
    "    stained[:,:,0] *= r_stain\n",
    "    stained[:,:,1] *= g_stain\n",
    "    stained[:,:,2] *= b_stain\n",
    "    \n",
    "    return Image.fromarray(np.clip(stained, 0, 255).astype(np.uint8))\n",
    "\n",
    "source_image = create_stained_image(0.9, 0.7, 0.85)\n",
    "target_image = create_stained_image(1.0, 0.8, 0.7)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(source_image)\n",
    "axes[0].set_title('Source Image')\n",
    "axes[1].imshow(target_image)\n",
    "axes[1].set_title('Target Image (Reference)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0953eb",
   "metadata": {},
   "source": [
    "### 1. Simple Normalization using Mean and Standard Deviation\n",
    "\n",
    "A common method is to scale the source image's color channels to match the mean and standard deviation of a target (reference) image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0efc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_color(source, target):\n",
    "    source_arr = np.array(source, dtype=np.float32)\n",
    "    target_arr = np.array(target, dtype=np.float32)\n",
    "    \n",
    "    normalized_arr = np.zeros_like(source_arr)\n",
    "    \n",
    "    for i in range(3): # For each channel (R, G, B)\n",
    "        source_channel = source_arr[:,:,i]\n",
    "        target_channel = target_arr[:,:,i]\n",
    "        \n",
    "        # Get stats\n",
    "        src_mean, src_std = np.mean(source_channel), np.std(source_channel)\n",
    "        tgt_mean, tgt_std = np.mean(target_channel), np.std(target_channel)\n",
    "        \n",
    "        # Normalize\n",
    "        normalized_channel = (source_channel - src_mean) / src_std * tgt_std + tgt_mean\n",
    "        normalized_arr[:,:,i] = normalized_channel\n",
    "        \n",
    "    return Image.fromarray(np.clip(normalized_arr, 0, 255).astype(np.uint8))\n",
    "\n",
    "normalized_image = normalize_color(source_image, target_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(source_image)\n",
    "axes[0].set_title('Source')\n",
    "axes[1].imshow(target_image)\n",
    "axes[1].set_title('Target')\n",
    "axes[2].imshow(normalized_image)\n",
    "axes[2].set_title('Normalized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f366077",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Check\n",
    "\n",
    "Let's check the mean of the normalized image's channels. They should be closer to the target's channel means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_means = np.mean(np.array(source_image), axis=(0,1))\n",
    "target_means = np.mean(np.array(target_image), axis=(0,1))\n",
    "normalized_means = np.mean(np.array(normalized_image), axis=(0,1))\n",
    "\n",
    "print(f\"Source means: {source_means}\")\n",
    "print(f\"Target means: {target_means}\")\n",
    "print(f\"Normalized means: {normalized_means}\")\n",
    "\n",
    "# Check if normalized means are closer to target means\n",
    "assert np.all(np.abs(normalized_means - target_means) < np.abs(source_means - target_means))\n",
    "\n",
    "print(\"\\nSUCCESS: Normalized image stats are closer to the target.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
